{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, inspect, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "CURRENT_DIR = os.path.dirname(inspect.getabsfile(inspect.currentframe()))\n",
    "ROOT_DIR = os.path.dirname(CURRENT_DIR)\n",
    "sys.path.insert(0, ROOT_DIR)\n",
    "\n",
    "from reb.src.pyts import series_to_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly date range generator\n",
    "def month_range(start_date, n_months):\n",
    "    for m in range(n_months):\n",
    "        yield start_date + relativedelta(months=+m)\n",
    "        \n",
    "# get all combinations of input iterable x\n",
    "def get_combinations(x):\n",
    "    rval = []\n",
    "    for L in range(1, len(x)+1):\n",
    "        for subset in itertools.combinations(x, L):\n",
    "            rval.append(list(subset))\n",
    "            \n",
    "    return rval      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "ffname = os.path.join(ROOT_DIR, \"reb\", \"data\", \"ext\", \"data_monthly_processed.csv\")\n",
    "df_original = pd.read_csv(ffname, parse_dates=[\"DATE\"])\n",
    "df_original.DATE = pd.to_datetime(df_original.DATE, format=\"%Y-%m\")\n",
    "df_original.head()\n",
    "\n",
    "# Make a clean copy of data\n",
    "df = df_original.copy() \n",
    "\n",
    "# Reindex data frame per the time stamps\n",
    "df.set_index(\"DATE\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "all_values = df.values.astype(\"float32\")\n",
    "all_values_scaled = scaler.fit_transform(all_values)\n",
    "ffname = os.path.join(ROOT_DIR, \"reb\", \"data\", \"int\", \"monthly.scaler.save\")\n",
    "joblib.dump(scaler, ffname) \n",
    "scaler = joblib.load(ffname) \n",
    "# USRECM: NBER based Recession Indicators for the United States from the Peak through the Trough\n",
    "# index_target = NA\n",
    "\n",
    "# GDPC1: Real Gross Domestic Product\n",
    "# index_target = NA\n",
    "\n",
    "# W875RX1: Real personal income excluding current transfer receipts\n",
    "# index_target = 13\n",
    "\n",
    "# PAYEMS: All Employees: Total Nonfarm Payrolls\n",
    "index_target = 0\n",
    "\n",
    "# INDPRO: Industrial Production Index\n",
    "# index_target = 11\n",
    "\n",
    "# CMRMTSPL: Real Manufacturing and Trade Industries Sales\n",
    "# index_target = 12\n",
    "\n",
    "variable_label = df.columns[index_target]\n",
    "features = list(range(all_values_scaled.shape[1]))\n",
    "del features[index_target]\n",
    "feature_combinations = get_combinations(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(feature_combinations)):\n",
    "# for j in range(5):\n",
    "    n_lags = 24\n",
    "    n_sequences = 18\n",
    "    n_units = 10\n",
    "    comb = feature_combinations[j]\n",
    "    fname = 'f.' +'.'.join([str(elem) for elem in comb]) + \\\n",
    "        f'.t.{index_target}.l.{n_lags}.s{n_sequences}.u.{n_units}' + '.h5'\n",
    "    \n",
    "    print(f\"model: {fname}\")\n",
    "\n",
    "    values_scaled = all_values_scaled[:, comb + [index_target]]\n",
    "    n_variables = values_scaled.shape[1]\n",
    "    # set model parameters\n",
    "    n_train = int(values_scaled.shape[0] * 0.8)\n",
    "\n",
    "    # set train parameters\n",
    "    optimizer = \"adam\"\n",
    "    loss = \"mse\"\n",
    "    n_epochs = 30\n",
    "    sz_batch = 20\n",
    "    verbose = 1\n",
    "\n",
    "    df_reframed = series_to_supervised(values_scaled, n_lags, n_sequences)\n",
    "    \n",
    "    # [print(elem) for elem in df_reframed.columns]\n",
    "\n",
    "    # create train/valid data\n",
    "    # split into train and test sets\n",
    "    values = df_reframed.values\n",
    "    train_values, valid_values = values[:n_train, :], values[n_train:, :]\n",
    "    print(f\"Train Inputs Shape: {train_values.shape}\")\n",
    "    print(f\"Valid Inputs Shape: {valid_values.shape}\")\n",
    "    \n",
    "    # split into input and targets\n",
    "    n_train, n_ = train_values.shape\n",
    "    n_valid, n_ = valid_values.shape\n",
    "    n_features = n_lags * n_variables\n",
    "    \n",
    "    x_train, y_train = train_values[:, :n_features], train_values[:, n_features+n_variables-1:n_:n_variables]\n",
    "    x_valid, y_valid = valid_values[:, :n_features], valid_values[:, n_features+n_variables-1:n_:n_variables]\n",
    "    print(f\"Train Inputs Shape: {x_train.shape}, Train Targets Shape: {y_train.shape}\")\n",
    "    print(f\"Valid Inputs Shape: {x_valid.shape}, Valid Targets Shape: {y_valid.shape}\")\n",
    "    \n",
    "    # reshape data as required by ltsm\n",
    "    x_train = x_train.reshape((n_train, n_lags, n_variables))\n",
    "    x_valid = x_valid.reshape((n_valid, n_lags, n_variables))\n",
    "    print(f\"Train Inputs Shape: {x_train.shape}, Train Targets Shape: {y_train.shape}\")\n",
    "    print(f\"Valid Inputs Shape: {x_valid.shape}, Valid Targets Shape: {y_valid.shape}\")\n",
    "    \n",
    "    # build model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_units, input_shape=(n_lags, n_variables)))\n",
    "    model.add(Dense(n_sequences))\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    # train model\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=n_epochs,\n",
    "                        batch_size=sz_batch,\n",
    "                        validation_data=(x_valid, y_valid),\n",
    "                        verbose=verbose,\n",
    "                        shuffle=False)\n",
    "   # Creates a HDF5 file 'my_model.h5'\n",
    "    ffname = os.path.join(ROOT_DIR, \"reb\", \"data\", \"int\", fname)\n",
    "    model.save(ffname)\n",
    "    \n",
    "    # plot history\n",
    "    figsize = (12, 7)\n",
    "    titlefontsize = 20\n",
    "    xtickfontsize = 15\n",
    "    ytickfontsize = 15\n",
    "    labelfontsize = 19\n",
    "    legendfontsize = 19\n",
    "    linewidth = 3\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.subplots(1, 1)\n",
    "    ax.plot(np.arange(1, n_epochs+1), history.history['loss'],\n",
    "            \"-\",\n",
    "            linewidth=linewidth,\n",
    "            label='Train Loss')\n",
    "    ax.plot(np.arange(1, n_epochs+1), history.history['val_loss'],\n",
    "            \"-\",\n",
    "            linewidth=linewidth,\n",
    "            label='Valid Loss')\n",
    "    ax.set_xlabel(\"Epoch #\", fontsize=labelfontsize)\n",
    "    ax.set_ylabel(\"Loss - \" + loss.upper(), fontsize=labelfontsize)\n",
    "    ax.tick_params(\n",
    "        axis='x',          \n",
    "        which='both',      \n",
    "        labelsize=xtickfontsize)\n",
    "    ax.tick_params(\n",
    "        axis='y',    \n",
    "        labelsize=ytickfontsize)\n",
    "    ax.set_title(\"Train Loss \" +  f\"({loss})\".upper() + \" vs Epoch\",\n",
    "            fontsize=titlefontsize,\n",
    "            fontweight=\"bold\"\n",
    "        )\n",
    "    ax.legend(loc=\"upper right\",\n",
    "              fontsize=legendfontsize,\n",
    "              framealpha=0.8,\n",
    "              fancybox=True,\n",
    "              frameon=True,\n",
    "              shadow=False,\n",
    "              edgecolor=\"k\")\n",
    "    ax.set_xlim([0, n_epochs+1])\n",
    "    plt.tight_layout()\n",
    "#     fname = f\"loss-plot-valid.png\"\n",
    "    # fig.savefig(os.path.join(ROOT_DIR, \"reports\", \"figures\", fname), transparent=False, dpi=dpi)\n",
    "    plt.show()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reb]",
   "language": "python",
   "name": "conda-env-reb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
