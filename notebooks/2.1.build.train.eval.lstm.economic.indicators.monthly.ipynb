{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, inspect, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "CURRENT_DIR = os.path.dirname(inspect.getabsfile(inspect.currentframe()))\n",
    "ROOT_DIR = os.path.dirname(CURRENT_DIR)\n",
    "sys.path.insert(0, ROOT_DIR)\n",
    "\n",
    "from reb.src.pyts import series_to_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffname = os.path.join(ROOT_DIR, \"reb\", \"data\", \"ext\", \"data_monthly_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ffname, parse_dates=[\"DATE\"])\n",
    "df.DATE = pd.to_datetime(df.DATE, format=\"%Y-%m\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a clen copy of data. This allows us to modify freely while we have always the original data for any further reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reindex data frame per the time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"DATE\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale data\n",
    "values = df.values\n",
    "values = values.astype(\"float32\")\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "values_scaled = scaler.fit_transform(values)\n",
    "n_variables = values.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_target = 15\n",
    "# set model parameters\n",
    "n_lags = 6\n",
    "n_sequences = 6\n",
    "n_train = int(values.shape[0] * 0.8)\n",
    "n_units = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set train parameters\n",
    "optimizer = \"adam\"\n",
    "loss = \"mse\"\n",
    "n_epochs = 20\n",
    "sz_batch = 10\n",
    "verbose = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reframed = series_to_supervised(values_scaled, n_lags, n_sequences)\n",
    "df_reframed.head()\n",
    "# [print(elem) for elem in df_reframed.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/valid data\n",
    "# split into train and test sets\n",
    "values = df_reframed.values\n",
    "train_values, valid_values = values[:n_train, :], values[n_train:, :]\n",
    "print(f\"Train Inputs Shape: {train_values.shape}\")\n",
    "print(f\"Valid Inputs Shape: {valid_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and targets\n",
    "n_train, n_ = train_values.shape\n",
    "n_valid, n_ = valid_values.shape\n",
    "n_features = n_lags * n_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and targets\n",
    "n_train, n_ = train_values.shape\n",
    "n_valid, n_ = valid_values.shape\n",
    "n_features = n_lags * n_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and targets\n",
    "n_train, n_ = train_values.shape\n",
    "n_valid, n_ = valid_values.shape\n",
    "n_observations = n_lags * n_variables\n",
    "x_train, y_train = train_values[:, :n_observations], train_values[:, n_observations+index_target:n_:n_variables]\n",
    "x_valid, y_valid = valid_values[:, :n_observations], valid_values[:, n_observations+index_target:n_:n_variables]\n",
    "print(f\"Train Inputs Shape: {x_train.shape}, Train Targets Shape: {y_train.shape}\")\n",
    "print(f\"Valid Inputs Shape: {x_valid.shape}, Valid Targets Shape: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data as required by ltsm\n",
    "x_train = x_train.reshape((n_train, n_lags, n_variables))\n",
    "x_valid = x_valid.reshape((n_valid, n_lags, n_variables))\n",
    "print(f\"Train Inputs Shape: {x_train.shape}, Train Targets Shape: {y_train.shape}\")\n",
    "print(f\"Valid Inputs Shape: {x_valid.shape}, Valid Targets Shape: {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_units, input_shape=(n_lags, n_variables)))\n",
    "model.add(Dense(n_sequences))\n",
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=n_epochs,\n",
    "                    batch_size=sz_batch,\n",
    "                    validation_data=(x_valid, y_valid),\n",
    "                    verbose=verbose,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "figsize = (12, 7)\n",
    "titlefontsize = 20\n",
    "xtickfontsize = 15\n",
    "ytickfontsize = 15\n",
    "labelfontsize = 19\n",
    "legendfontsize = 19\n",
    "linewidth = 3\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.subplots(1, 1)\n",
    "ax.plot(np.arange(1, n_epochs+1), history.history['loss'],\n",
    "        \"-\",\n",
    "        linewidth=linewidth,\n",
    "        label='Train Loss')\n",
    "ax.plot(np.arange(1, n_epochs+1), history.history['val_loss'],\n",
    "        \"-\",\n",
    "        linewidth=linewidth,\n",
    "        label='Valid Loss')\n",
    "ax.set_xlabel(\"Epoch #\", fontsize=labelfontsize)\n",
    "ax.set_ylabel(\"Loss - \" + loss.upper(), fontsize=labelfontsize)\n",
    "ax.tick_params(\n",
    "    axis='x',          \n",
    "    which='both',      \n",
    "    labelsize=xtickfontsize)\n",
    "ax.tick_params(\n",
    "    axis='y',    \n",
    "    labelsize=ytickfontsize)\n",
    "ax.set_title(\"Train Loss \" +  f\"({loss})\".upper() + \" vs Epoch\",\n",
    "        fontsize=titlefontsize,\n",
    "        fontweight=\"bold\"\n",
    "    )\n",
    "ax.legend(loc=\"upper right\",\n",
    "          fontsize=legendfontsize,\n",
    "          framealpha=0.8,\n",
    "          fancybox=True,\n",
    "          frameon=True,\n",
    "          shadow=False,\n",
    "          edgecolor=\"k\")\n",
    "ax.set_xlim([0, n_epochs+1])\n",
    "plt.tight_layout()\n",
    "fname = f\"loss-plot-valid.png\"\n",
    "# fig.savefig(os.path.join(ROOT_DIR, \"reports\", \"figures\", fname), transparent=False, dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat_valid = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = x_valid.reshape((n_valid, n_lags*n_variables))\n",
    "temp[-n_sequences*n_variables:][:, index_target:n_sequences*n_variables:n_variables] = \\\n",
    "    y_valid.reshape((n_valid, n_sequences))\n",
    "temp = temp.reshape((-1, n_variables))\n",
    "y_valid = scaler.inverse_transform(temp)[:, index_target]\n",
    "\n",
    "temp = x_valid.reshape((n_valid, n_lags*n_variables))\n",
    "temp[-n_sequences*n_variables:][:, index_target:n_sequences*n_variables:n_variables] = \\\n",
    "    yhat_valid.reshape((n_valid, n_sequences))\n",
    "temp = temp.reshape((-1, n_variables))\n",
    "yhat_valid = scaler.inverse_transform(temp)[:, index_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 12\n",
    "ncols = 3\n",
    "fig, axs = plt.subplots(nrows=int(np.ceil(n/ncols)),\n",
    "                        ncols=ncols,\n",
    "                        figsize=(12, 22),\n",
    "                        sharex=True)\n",
    "for k in range(n):\n",
    "    i = k // ncols\n",
    "    j = k % ncols\n",
    "    axs[i, j].plot(np.arange(1,n_sequences+1),\n",
    "                   y_valid[i*n_sequences:i*n_sequences+n_sequences],\n",
    "                   color=\"blue\",\n",
    "                   label=\"True\")\n",
    "    axs[i, j].plot(np.arange(1,n_sequences+1),\n",
    "                   yhat_valid[i*n_sequences:i*n_sequences+n_sequences],\n",
    "                   color=\"black\",\n",
    "                   label=\"Predicted\")\n",
    "    \n",
    "    \n",
    "    axs[i, j].legend(loc=\"best\",\n",
    "                     fontsize=legendfontsize,\n",
    "                     framealpha=0.8,\n",
    "                     fancybox=True,\n",
    "                     frameon=True,\n",
    "                     shadow=False,\n",
    "                     edgecolor=\"k\")\n",
    "    \n",
    "    axs[i, j].set_ylim([0, 1.1*max(y_valid)])\n",
    "#     print(y_valid[i*n_sequences:i*n_sequences+n_sequences].shape) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reb]",
   "language": "python",
   "name": "conda-env-reb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
